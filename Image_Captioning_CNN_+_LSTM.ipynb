{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Automated Image Captioning using CNN + LSTM"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsvPqlCereqY"
   },
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import string\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization,LSTM,Embedding, Bidirectional, LSTM,Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from textwrap import wrap\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"dark\")\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKRIS_4OsTQR",
    "outputId": "4e2ecc28-f78e-4b06-a146-9c08413a35b6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "us_wUMsBrzaI"
   },
   "source": [
    "img_path = '/content/drive/MyDrive/Colab Notebooks/Captioning Dataset 2/Images'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Captioning Dataset 2/captions.txt/captions.txt\")\n",
    "data.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8T8zOBmBBl4O",
    "outputId": "2ed1a357-3290-47c7-c09d-f0a5e97a29fc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Extraction"
   ],
   "metadata": {
    "id": "cYg15d_eBmzU"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcILUzPosldm",
    "outputId": "120ddb10-362f-4291-86a9-8a26d408fb92"
   },
   "source": [
    "# Extract\n",
    "model = InceptionV3(weights='imagenet')\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "model.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# extract features from each photo in the directory\n",
    "def extract_features(directory):\n",
    "    # load the model\n",
    "    model = InceptionV3(weights='imagenet')\n",
    "    # re-structure the model\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "\n",
    "    # extract features from each photo\n",
    "    features = dict()\n",
    "    for name in listdir(directory):\n",
    "        # load an image from file\n",
    "        filename = directory + '/' + name\n",
    "        img = load_img(filename, target_size=(299, 299))\n",
    "        # convert the image to a numpy array\n",
    "        x = img_to_array(img)\n",
    "        # reshape data for the model\n",
    "        x = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))\n",
    "        # prepare the image for the Inception model\n",
    "        x = preprocess_input(x)\n",
    "        # get features\n",
    "        feature = model.predict(x, verbose=0)\n",
    "        # get image id\n",
    "        image_id = name.split('.')[0]\n",
    "        # store feature\n",
    "        features[image_id] = feature\n",
    "        print('>%s' % name)\n",
    "    return features"
   ],
   "metadata": {
    "id": "dmhUo4EnBvq1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7oCmCsgusnrS",
    "outputId": "497d30fe-c022-447b-f68b-e722b856b51a"
   },
   "source": [
    "# extract features from all images\n",
    "directory = img_path\n",
    "features = extract_features(directory)\n",
    "print('Extracted Features: %d' % len(features))\n",
    "# save to file\n",
    "pickle.dump(features, open('features.pkl', 'wb'))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pickle.dump(features, open('features.pkl', 'wb'))"
   ],
   "metadata": {
    "id": "MC74m46o2U7k"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNLVXeaQsubr"
   },
   "source": [
    "# # load features\n",
    "# with open('/content/features.pkl','rb') as f:\n",
    "#     features = pickle.load(f)\n",
    "\n",
    "with open('/content/drive/MyDrive/Colab Notebooks/Captioning Dataset 2/features.pkl','rb') as f:\n",
    "    features = pickle.load(f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PWmr-yTZZcy"
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbBqRYYQZbW0"
   },
   "source": [
    "with open(os.path.join(img_path,'/content/drive/MyDrive/Colab Notebooks/Captioning Dataset 2/captions.txt/captions.txt'),'r') as f:\n",
    "    next(f)\n",
    "    captions_doc = f.read()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a67997510fb84940a51e9d3e8f8ee996",
      "848b024f4f1d4978980d2abe57c71c64",
      "56902618db8b4b32a5d54031c5b1fd2a",
      "b8e8c2ca6bd04176a60e71cac7b8936a",
      "ee9e0da1f54c4806b5076a76c0793907",
      "abe2b8d5aca0428794cdedd134e94a3e",
      "e6c47fcf151148268a1f32d05f7262ae",
      "135111f98d1d4b70bd695b753ccbea5e",
      "dba430f0bff1457bbccad79a8d3dd148",
      "6fabbf76e5484f7db8b67057ed70721a",
      "00572398919445beaddc1932fe7ddc48"
     ]
    },
    "id": "BOIjHq6Uafk4",
    "outputId": "c565520e-8f0c-498f-f6f6-70ebb7f12f45"
   },
   "source": [
    "# create mapping of image to captions\n",
    "mapping = {}\n",
    "# process lines\n",
    "for line in tqdm(captions_doc.split('\\n')):\n",
    "    # split the line by comma(,)\n",
    "    tokens = line.split(',')\n",
    "    if len(line) < 2:\n",
    "        continue\n",
    "    image_id, caption = tokens[0], tokens[1:]\n",
    "    # remove extension from image ID\n",
    "    image_id = image_id.split('.')[0]\n",
    "    # convert caption list to string\n",
    "    caption = \" \".join(caption)\n",
    "    # create list if needed\n",
    "    if image_id not in mapping:\n",
    "        mapping[image_id] = []\n",
    "    # store the caption\n",
    "    mapping[image_id].append(caption)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBqe-ouzbGCy",
    "outputId": "b37e512c-cd40-4385-820a-55e20e25ce37"
   },
   "source": [
    "len(mapping)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLSy2_9mbN1U"
   },
   "source": [
    "# Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GZ2WSQEbIQB"
   },
   "source": [
    "def clean(mapping):\n",
    "    for key, captions in mapping.items():\n",
    "        for i in range(len(captions)):\n",
    "            # take one caption at a time\n",
    "            caption = captions[i]\n",
    "            # preprocessing steps\n",
    "            # convert to lowercase\n",
    "            caption = caption.lower()\n",
    "            # delete digits, special chars, etc.,\n",
    "            caption = caption.replace('[^A-Za-z]', '')\n",
    "            # delete additional spaces\n",
    "            caption = caption.replace('\\s+', ' ')\n",
    "            # add start and end tags to the caption\n",
    "            caption = 'startseq ' + \" \".join([word for word in caption.split() if len(word)>1]) + ' endseq'\n",
    "            captions[i] = caption"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_3E8O5dbSrS"
   },
   "source": [
    "# process text\n",
    "clean(mapping)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mapping"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2KR1K1URp7t",
    "outputId": "7e79569f-8c7a-417b-fda4-8f3de5d81431"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLVW4uGybUa3"
   },
   "source": [
    "all_captions = []\n",
    "for key in mapping:\n",
    "    for caption in mapping[key]:\n",
    "        all_captions.append(caption)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iC4DObylbXA1",
    "outputId": "3b146336-2064-4589-b820-5520a1c07dbd"
   },
   "source": [
    "len(all_captions)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDNsqwGDbZsW",
    "outputId": "b94a90bf-8791-47a4-872d-415a2294eefc"
   },
   "source": [
    "all_captions[:10]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KN87wT0wcBzw"
   },
   "source": [
    "# Tokenize the Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQo8Nf39bhJM"
   },
   "source": [
    "# tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okeRm5Hwb2lz"
   },
   "source": [
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQDfeGSUb5MM",
    "outputId": "462288ba-2170-487c-de13-a29cfc49b489"
   },
   "source": [
    "vocab_size"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7neF7FBRb6hJ",
    "outputId": "7c3a66ba-2edd-4099-bbef-4e131ed7c3e3"
   },
   "source": [
    "# get maximum len of the captions available\n",
    "max_length = max(len(caption.split()) for caption in all_captions)\n",
    "max_length"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyqQPM9vchi5"
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0j411U8b8gC"
   },
   "source": [
    "image_ids = list(mapping.keys())\n",
    "split = int(len(image_ids)  * 0.90)\n",
    "train = image_ids[:split]\n",
    "test = image_ids[split:]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rfjOm9Nb_hP",
    "outputId": "26cfe160-f3c7-4dff-c150-e54ed4d81dab"
   },
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiZz6aOvcnPF"
   },
   "source": [
    "# Create Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-YIysLVcWRY"
   },
   "source": [
    "def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
    "    # Loop over images\n",
    "    x1, x2, y = list(), list(), list()\n",
    "    n = 0\n",
    "    while 1:\n",
    "        for key in data_keys:\n",
    "            n += 1\n",
    "            captions = mapping[key]\n",
    "            # process each caption\n",
    "            for caption in captions:\n",
    "                # encode the sequence\n",
    "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "                # Spllt the squences into x,y pairs\n",
    "                for i in range(1, len(seq)):\n",
    "                    # split into input and output pairs\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    # pad input sequence\n",
    "                    in_seq  = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                    # encode output sequence\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\n",
    "                    # store the sequeces\n",
    "                    x1.append(features[key][0])\n",
    "                    x2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "\n",
    "                if n == batch_size:\n",
    "                    x1,x2,y = np.array(x1), np.array(x2), np.array(y)\n",
    "                    yield[x1,x2], y\n",
    "                    x1, x2, y = list(), list(), list()\n",
    "                    n = 0"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKBNJM4Scw5l"
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yb8Xc0soctcr"
   },
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM,BatchNormalization,Concatenate\n",
    "\n",
    "# Encoder model\n",
    "inputs1 = Input(shape=(2048,))\n",
    "fe1 = BatchNormalization()(inputs1)\n",
    "fe2 = Dense(512, activation='relu')(fe1)\n",
    "\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "se1 = Embedding(vocab_size, 512, mask_zero=True)(inputs2)\n",
    "se2 = BatchNormalization()(se1)\n",
    "se3 = Bidirectional(LSTM(256))(se2)\n",
    "\n",
    "# Decoder\n",
    "decoder = Concatenate()([fe2, se3])\n",
    "decoder2 = Dense(512, activation='relu')(decoder)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "optimizer = Adam(learning_rate=0.0001, clipvalue=5.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBFMv6Bde6Wp"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define parameters\n",
    "model_name = 'model.h5'\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(train) // batch_size\n",
    "validation_steps = len(test) // batch_size"
   ],
   "metadata": {
    "id": "cjsQgKyVXwn-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_generator = data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
    "validation_generator = data_generator(test, mapping, features, tokenizer, max_length, vocab_size, batch_size)"
   ],
   "metadata": {
    "id": "JrIBB1swXpnZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kta2URvXerjb",
    "outputId": "cc524241-f205-4435-ebec-fc73ab28b3b7"
   },
   "source": [
    "# Define callbacks\n",
    "checkpoint_filepath = 'model_checkpoint.h5'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',min_delta = 0, patience = 5, verbose = 1, restore_best_weights=True)\n",
    "\n",
    "# Training\n",
    "history = model.fit(train_generator, validation_data=validation_generator, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, verbose=1, callbacks=[checkpoint, earlystopping])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPPfMvP7fm76",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "outputId": "60505081-2e22-43b8-c03f-8ac4d0a28714"
   },
   "source": [
    "plot_model(model)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3-scT8JO-y_",
    "outputId": "3c51d4ed-1664-4a97-d7ca-c592b1268f4f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Save model\n",
    "model.save('model.h5')"
   ],
   "metadata": {
    "id": "Y1lJ3Tyx6Xto"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performance Evaluation"
   ],
   "metadata": {
    "id": "TFjelpCoTDmd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "XlH6-MyZjptC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "outputId": "f5d2aab9-1ae3-4311-d5d4-eb3c694acf0b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Caption Generation"
   ],
   "metadata": {
    "id": "aBcfzZmW_wXz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def idx_to_word(integer,tokenizer):\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index==integer:\n",
    "            return word\n",
    "    return None"
   ],
   "metadata": {
    "id": "5Cmk8Slt6ZuK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_caption(model, image, tokenizer, max_length, features):\n",
    "\n",
    "    feature = features[image]\n",
    "    in_text = \"startseq\"\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], max_length)\n",
    "\n",
    "        y_pred = model.predict([feature,sequence])\n",
    "        y_pred = np.argmax(y_pred)\n",
    "\n",
    "        word = idx_to_word(y_pred, tokenizer)\n",
    "\n",
    "        if word is None:\n",
    "            break\n",
    "\n",
    "        in_text+= \" \" + word\n",
    "\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "\n",
    "    return in_text"
   ],
   "metadata": {
    "id": "LuA08ahGTG-u"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def readImage(path,img_size=224):\n",
    "    img = load_img(path,color_mode='rgb',target_size=(img_size,img_size))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255.\n",
    "\n",
    "    return img\n",
    "\n",
    "def display_images(temp_df):\n",
    "    temp_df = temp_df.reset_index(drop=True)\n",
    "    plt.figure(figsize = (20 , 20))\n",
    "    n = 0\n",
    "    for i in range(15):\n",
    "        n+=1\n",
    "        plt.subplot(5 , 5, n)\n",
    "        plt.subplots_adjust(hspace = 0.7, wspace = 0.3)\n",
    "        image = readImage(f\"/content/drive/MyDrive/Colab Notebooks/Captioning Dataset 2/Images/{temp_df.image[i]}.jpg\")\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"\\n\".join(wrap(temp_df.caption[i], 20)))\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "id": "N2_07Pd7CAlr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model"
   ],
   "metadata": {
    "id": "TH0sRSs7aUvP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# load the tokenizer\n",
    "tokenizer = pickle.load(open('tokenizer.pkl', 'rb'))\n",
    "# Load Features\n",
    "with open('/content/drive/MyDrive/Colab Notebooks/Captioning Dataset 2/features.pkl','rb') as f:\n",
    "    features = pickle.load(f)\n",
    "# pre-define the max sequence length (from training)\n",
    "max_length = 35\n",
    "# load the model\n",
    "model = load_model('/content/drive/MyDrive/Colab Notebooks/Captioning Dataset 2/model_3.55val.h5')"
   ],
   "metadata": {
    "id": "6thi_2WpabYo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Testing the model\n",
    "sample_df = pd.DataFrame(columns=[\"image\", \"caption\"])\n",
    "sample_list = []\n",
    "\n",
    "# Assuming test is a DataFrame with a column 'image'\n",
    "for i in range(15):\n",
    "    image = np.random.choice(test)\n",
    "    caption = predict_caption(model, image, tokenizer, max_length, features)\n",
    "    sample_list.append(pd.DataFrame({\"image\": [image], \"caption\": [caption]}))\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "sample_df = pd.concat(sample_list, ignore_index=True)\n",
    "\n",
    "print(sample_df)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnR5ivEX_3KX",
    "outputId": "dcae26f3-08ce-43dc-fa7f-2cad51a784fa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "display_images(sample_df)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 940
    },
    "id": "jjN1bmHqALzR",
    "outputId": "9a86a96e-2e23-41fb-ab21-7eb31228eddd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate Model with BLEU SCORE\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
    "    actual, predicted = list(), list()\n",
    "    # step over the whole set\n",
    "    for key, desc_list in descriptions.items():\n",
    "        # generate description\n",
    "        yhat = predict_caption(model, key, tokenizer, max_length, photos)\n",
    "        # store actual and predicted\n",
    "        references = [d.split() for d in desc_list]\n",
    "        actual.append(references)\n",
    "        predicted.append(yhat.split())\n",
    "    # calculate BLEU score\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ],
   "metadata": {
    "id": "3PMNxJn0ImJU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_features = {image_id: features[image_id] for image_id in test}\n",
    "test_mapping = {image_id: mapping[image_id] for image_id in test}"
   ],
   "metadata": {
    "id": "3jWz0D69g6by"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(test_features))\n",
    "print(len(test_mapping))"
   ],
   "metadata": {
    "id": "45csoyy2wknt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# evaluate model\n",
    "evaluate_model(model, test_mapping, test_features, tokenizer, max_length)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFKxuEOMYvzT",
    "outputId": "06a6a5bd-5790-4ea0-fea7-f061f020ea9d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "bZi_3Gfpnc7M"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a67997510fb84940a51e9d3e8f8ee996": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_848b024f4f1d4978980d2abe57c71c64",
       "IPY_MODEL_56902618db8b4b32a5d54031c5b1fd2a",
       "IPY_MODEL_b8e8c2ca6bd04176a60e71cac7b8936a"
      ],
      "layout": "IPY_MODEL_ee9e0da1f54c4806b5076a76c0793907"
     }
    },
    "848b024f4f1d4978980d2abe57c71c64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abe2b8d5aca0428794cdedd134e94a3e",
      "placeholder": "​",
      "style": "IPY_MODEL_e6c47fcf151148268a1f32d05f7262ae",
      "value": "100%"
     }
    },
    "56902618db8b4b32a5d54031c5b1fd2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_135111f98d1d4b70bd695b753ccbea5e",
      "max": 40456,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dba430f0bff1457bbccad79a8d3dd148",
      "value": 40456
     }
    },
    "b8e8c2ca6bd04176a60e71cac7b8936a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fabbf76e5484f7db8b67057ed70721a",
      "placeholder": "​",
      "style": "IPY_MODEL_00572398919445beaddc1932fe7ddc48",
      "value": " 40456/40456 [00:00&lt;00:00, 427125.97it/s]"
     }
    },
    "ee9e0da1f54c4806b5076a76c0793907": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abe2b8d5aca0428794cdedd134e94a3e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6c47fcf151148268a1f32d05f7262ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "135111f98d1d4b70bd695b753ccbea5e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dba430f0bff1457bbccad79a8d3dd148": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6fabbf76e5484f7db8b67057ed70721a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "00572398919445beaddc1932fe7ddc48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
